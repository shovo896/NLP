{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93e42f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.fft as fft\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "311da84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9d04d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "datasets=load_dataset('wikitext','wikitext-2-raw-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6bd98ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/var/folders/79/qf4s258d1979pqm6v_z63bmc0000gn/T/ipykernel_1583/1055278940.py:4: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  text=re.sub('\\s\\s',' ',text)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47f28c1b7944e1d996c0ca82a8fe6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4ca45c3b4d4493a284d4e73f1d5602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2083 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dceb9b056f44cfcbd097aac6e05aa54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2383 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc0a5208674469fa2a7a3ae3a406d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/19530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a39ddbad5954aea8e06a68f3ef94d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2083 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabec10f4e6e44b3bcb3ce8e56e89b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2383 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(sentence):\n",
    "    text=sentence['text'].lower()\n",
    "    text=re.sub(r'[^a-zA-Z0-9\\s]','',text)\n",
    "    text=re.sub('\\s\\s',' ',text)\n",
    "    sentence['text']=text\n",
    "    return sentence\n",
    "datasets['train']=datasets['train'].map(preprocess_function)\n",
    "datasets['validation']=datasets['validation'].map(preprocess_function)\n",
    "datasets['test']=datasets['test'].map(preprocess_function)  \n",
    "\n",
    "\n",
    "datasets['train']=datasets['train'].filter(lambda example: len(example['text'])>20)\n",
    "datasets['validation']=datasets['validation'].filter(lambda example: len(example['text'])>20)\n",
    "datasets['test']=datasets['test'].filter(lambda example: len(example['text'])>20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cd4034",
   "metadata": {},
   "source": [
    "tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8ff2d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d9615c3f2894766a0911e8a60f41751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1265cf9ab2cd43c89844f19d1e8bbf20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a671ac3ab4f41248add675ef028d67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c885ae5df7d4e36a7801af872fdcb62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2333 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14f345fde5c49438791dd1a0db35403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19067 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a43b4215b954349886b99541daa9865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2034 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding \n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint='distilbert-base-uncased-finetuned-sst-2-english'\n",
    "tokenizer=AutoTokenizer.from_pretrained(checkpoint)\n",
    "def tokenize(sentence):\n",
    "    sentence=tokenizer(sentence['text'],truncation=True,max_length=512)\n",
    "    return sentence\n",
    "tokenized_inputs=datasets.map(tokenize,batched=True)\n",
    "tokenized_inputs.remove_columns(['text'])\n",
    "batch=16\n",
    "data_collator=DataCollatorWithPadding(tokenizer=tokenizer,padding=True,return_tensors='pt')\n",
    "dataloader=DataLoader(tokenized_inputs['train'],batch_size=batch,shuffle=True,collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7146aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncodding(torch.nn.Module):\n",
    "    def __init__(self,d_model,max_sequence_length):\n",
    "        super().__init__()\n",
    "        self.d_model=d_model\n",
    "        self.max_sequence_length=max_sequence_length\n",
    "        self.positional_encolding=self._generate_positional_encoding().to(device)\n",
    "    def create_positional_encoding(self):\n",
    "        positional_encoding=np.zeros((self.max_sequence_length,self.d_model))\n",
    "        for pos in range(self.max_sequence_length):\n",
    "            for i in range(0,self.d_model,2):\n",
    "                positional_encoding[pos,i]=np.sin(pos/(10000**((2*i)/self.d_model)))\n",
    "                if i+1<self.d_model:\n",
    "                    positional_encoding[pos,i+1]=np.cos(pos/(10000**((2*(i+1))/self.d_model)))\n",
    "        return torch.from_numpy(positional_encoding).float()\n",
    "    def forward(self,x):\n",
    "        expanded_tensor=torch.unsquedeze(self.positional_encolding,0).expand(x.size(0),-1,-1).to(device)\n",
    "        return x.to(device)+expanded_tensor[:,:x.size(1),:]\n",
    "    class PositionalEncodding(nn.Module):\n",
    "        def __init__(self,sequece_length,vocab_size,embed_dim):\n",
    "            super(PositionalEncodding,self).__init__()\n",
    "            self.token_enmbedding=nn.Embedding(vocab_size,embed_dim)\n",
    "            self.position_embedding=PositionalEncodding(embed_dim,sequence_length)\n",
    "        def forward(self,x):\n",
    "            embedded_tokens=self.token_enmbedding(inputs).to(device)\n",
    "            embedded_positions=self.position_embedding(embedded_tokens).to(device)\n",
    "            return embedded_positions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
