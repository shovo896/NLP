{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd3a5dce",
   "metadata": {},
   "source": [
    "! pip install youtube-comment-downloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d1d4a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_comment_downloader import YoutubeCommentDownloader\n",
    "import pandas as pd\n",
    "import time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde7aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#video_id ber korte hobe \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16fa85c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading comments for video: K0B2qlb8eVI\n",
      "  Collected 50 comments from K0B2qlb8eVI...\n",
      "  Collected 100 comments from K0B2qlb8eVI...\n",
      "  Collected 150 comments from K0B2qlb8eVI...\n",
      "  Collected 200 comments from K0B2qlb8eVI...\n",
      "  Reached limit (200) for K0B2qlb8eVI\n",
      "Downloading comments for video: 5NLf7O6BF6s\n",
      "  Collected 50 comments from 5NLf7O6BF6s...\n",
      "  Collected 100 comments from 5NLf7O6BF6s...\n",
      "  Collected 150 comments from 5NLf7O6BF6s...\n",
      "  Collected 200 comments from 5NLf7O6BF6s...\n",
      "  Reached limit (200) for 5NLf7O6BF6s\n",
      "Comments downloaded and saved to youtube_comments.csv. Total rows: 400\n"
     ]
    }
   ],
   "source": [
    "video_ids = [\n",
    "    \"K0B2qlb8eVI\",\n",
    "    \"5NLf7O6BF6s\"\n",
    "]\n",
    "\n",
    "MAX_COMMENTS_PER_VIDEO = 200\n",
    "SLEEP_SECONDS = 0.000001\n",
    "\n",
    "downloader = YoutubeCommentDownloader()\n",
    "all_data = []\n",
    "\n",
    "for vid in video_ids:\n",
    "    print(f\"Downloading comments for video: {vid}\")\n",
    "    url = f\"https://www.youtube.com/watch?v={vid}\"\n",
    "\n",
    "    try:\n",
    "        comments = downloader.get_comments_from_url(url)\n",
    "        for idx, comment in enumerate(comments, start=1):\n",
    "            # Some videos/comments do not include all fields (e.g., likes).\n",
    "            likes = comment.get(\"likes\", comment.get(\"votes\", 0))\n",
    "            all_data.append({\n",
    "                \"video_id\": vid,\n",
    "                \"comment\": comment.get(\"text\", \"\"),\n",
    "                \"author\": comment.get(\"author\", \"\"),\n",
    "                \"likes\": likes,\n",
    "                \"published_at\": comment.get(\"published_at\", comment.get(\"time\", \"\"))\n",
    "            })\n",
    "\n",
    "            if idx % 50 == 0:\n",
    "                print(f\"  Collected {idx} comments from {vid}...\")\n",
    "\n",
    "            if idx >= MAX_COMMENTS_PER_VIDEO:\n",
    "                print(f\"  Reached limit ({MAX_COMMENTS_PER_VIDEO}) for {vid}\")\n",
    "                break\n",
    "\n",
    "            time.sleep(SLEEP_SECONDS)\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading comments for video {vid}: {e}\")\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "df.to_csv(\"youtube_comments.csv\", index=False, encoding='utf-8-sig')\n",
    "print(f\"Comments downloaded and saved to youtube_comments.csv. Total rows: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60bb922",
   "metadata": {},
   "source": [
    "nlp - preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d28f4c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: spacy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.8.11)\n",
      "Collecting emoji\n",
      "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m36m-:--:--\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk) (8.3.1)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/imac/Library/Python/3.12/lib/python/site-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (0.21.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (2.12.5)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/imac/Library/Python/3.12/lib/python/site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
      "Requirement already satisfied: six in /Users/imac/Library/Python/3.12/lib/python/site-packages (from langdetect) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->spacy) (3.0.3)\n",
      "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993332 sha256=80496222a29ebea642e1bb0f0f40d924345a62e2bfb561f4db7ced38669789c6\n",
      "  Stored in directory: /Users/imac/Library/Caches/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect, emoji\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [emoji]\n",
      "\u001b[1A\u001b[2KSuccessfully installed emoji-2.15.0 langdetect-1.0.9\n"
     ]
    }
   ],
   "source": [
    "! pip install  nltk spacy emoji langdetect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29424ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.8.11)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (0.21.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (2.12.5)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/imac/Library/Python/3.12/lib/python/site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->spacy) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6f03c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m113.9 kB/s\u001b[0m  \u001b[33m0:01:16\u001b[0m0:00:03\u001b[0m00:05\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a17db909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Spacy model 'en_core_web_sm' is already installed and working!\n"
     ]
    }
   ],
   "source": [
    "# Test if spacy model is already available\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(\"✓ Spacy model 'en_core_web_sm' is already installed and working!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "088f4dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re \n",
    "import nltk \n",
    "import spacy \n",
    "import emoji \n",
    "from langdetect import detect \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ebc5dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/imac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/imac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bf4df8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>likes</th>\n",
       "      <th>published_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>India is a very powerful country</td>\n",
       "      <td>@BoazMwadime-b1k</td>\n",
       "      <td>0</td>\n",
       "      <td>6 ঘণ্টা আগে</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>Common denominator with all Islamist is they a...</td>\n",
       "      <td>@clevelandwilliams5922</td>\n",
       "      <td>0</td>\n",
       "      <td>12 ঘণ্টা আগে</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>Let’s talk about all the children that disappe...</td>\n",
       "      <td>@PeterWright-y3b</td>\n",
       "      <td>0</td>\n",
       "      <td>15 ঘণ্টা আগে</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>So they sent the master of disaster</td>\n",
       "      <td>@andrewpetersen6116</td>\n",
       "      <td>0</td>\n",
       "      <td>15 ঘণ্টা আগে</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>Muslims wanted Pakistan and killed hindus for ...</td>\n",
       "      <td>@AshishVerma-dz9ug</td>\n",
       "      <td>0</td>\n",
       "      <td>1 দিন আগে</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment  \\\n",
       "0  K0B2qlb8eVI                   India is a very powerful country   \n",
       "1  K0B2qlb8eVI  Common denominator with all Islamist is they a...   \n",
       "2  K0B2qlb8eVI  Let’s talk about all the children that disappe...   \n",
       "3  K0B2qlb8eVI                So they sent the master of disaster   \n",
       "4  K0B2qlb8eVI  Muslims wanted Pakistan and killed hindus for ...   \n",
       "\n",
       "                   author  likes  published_at  \n",
       "0        @BoazMwadime-b1k      0   6 ঘণ্টা আগে  \n",
       "1  @clevelandwilliams5922      0  12 ঘণ্টা আগে  \n",
       "2        @PeterWright-y3b      0  15 ঘণ্টা আগে  \n",
       "3     @andrewpetersen6116      0  15 ঘণ্টা আগে  \n",
       "4      @AshishVerma-dz9ug      0     1 দিন আগে  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"youtube_comments.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43c01d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified comment column: comment\n"
     ]
    }
   ],
   "source": [
    "comment_column = None\n",
    "\n",
    "# 1) Preferred exact/keyword matches\n",
    "priority_names = {\"comment\", \"comments\", \"text\", \"review\", \"message\", \"body\"}\n",
    "for col in df.columns:\n",
    "    col_l = str(col).strip().lower()\n",
    "    if col_l in priority_names or any(k in col_l for k in [\"comment\", \"text\", \"review\", \"message\"]):\n",
    "        comment_column = col\n",
    "        break\n",
    "\n",
    "# 2) Fallback: first object/string-like column with non-empty values\n",
    "if comment_column is None:\n",
    "    for col in df.columns:\n",
    "        series = df[col]\n",
    "        if series.dtype == \"object\" and series.dropna().astype(str).str.strip().ne(\"\").any():\n",
    "            comment_column = col\n",
    "            break\n",
    "\n",
    "print(f\"Identified comment column: {comment_column}\")\n",
    "if comment_column is None:\n",
    "    raise ValueError(f\"Could not identify a comment/text column. Available columns: {list(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ec61fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def clean_text_nlp(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\",\"unknown\"\n",
    "    text=str(text)\n",
    "    # try urls \n",
    "    try:\n",
    "        lang=detect(text)\n",
    "    except:\n",
    "        lang=\"unknown\"\n",
    "    # remove emojis\n",
    "    text=emoji.replace_emoji(text,replace=\"\")\n",
    "    # remove urls\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text=text.lower()\n",
    "    #keep english and bangla letters \n",
    "    text = re.sub(r\"[^a-zA-Z\\u0980-\\u09FF\\s]\", \"\", text)\n",
    "    # tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # lemmatize\n",
    "    doc = nlp(\" \".join(tokens))\n",
    "    lemmas=[token.lemma_ for token in doc]\n",
    "    cleaned_text=\" \".join(lemmas)\n",
    "    return cleaned_text,lang\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dfe489",
   "metadata": {},
   "source": [
    "apply preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3cbc5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>likes</th>\n",
       "      <th>published_at</th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>India is a very powerful country</td>\n",
       "      <td>@BoazMwadime-b1k</td>\n",
       "      <td>0</td>\n",
       "      <td>6 ঘণ্টা আগে</td>\n",
       "      <td>india powerful country</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>Common denominator with all Islamist is they a...</td>\n",
       "      <td>@clevelandwilliams5922</td>\n",
       "      <td>0</td>\n",
       "      <td>12 ঘণ্টা আগে</td>\n",
       "      <td>common denominator islamist attach cause separ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>Let’s talk about all the children that disappe...</td>\n",
       "      <td>@PeterWright-y3b</td>\n",
       "      <td>0</td>\n",
       "      <td>15 ঘণ্টা আগে</td>\n",
       "      <td>let talk child disappear mountbatten indian le...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>So they sent the master of disaster</td>\n",
       "      <td>@andrewpetersen6116</td>\n",
       "      <td>0</td>\n",
       "      <td>15 ঘণ্টা আগে</td>\n",
       "      <td>send master disaster</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>Muslims wanted Pakistan and killed hindus for ...</td>\n",
       "      <td>@AshishVerma-dz9ug</td>\n",
       "      <td>0</td>\n",
       "      <td>1 দিন আগে</td>\n",
       "      <td>muslims want pakistan kill hindus million musl...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment  \\\n",
       "0  K0B2qlb8eVI                   India is a very powerful country   \n",
       "1  K0B2qlb8eVI  Common denominator with all Islamist is they a...   \n",
       "2  K0B2qlb8eVI  Let’s talk about all the children that disappe...   \n",
       "3  K0B2qlb8eVI                So they sent the master of disaster   \n",
       "4  K0B2qlb8eVI  Muslims wanted Pakistan and killed hindus for ...   \n",
       "\n",
       "                   author  likes  published_at  \\\n",
       "0        @BoazMwadime-b1k      0   6 ঘণ্টা আগে   \n",
       "1  @clevelandwilliams5922      0  12 ঘণ্টা আগে   \n",
       "2        @PeterWright-y3b      0  15 ঘণ্টা আগে   \n",
       "3     @andrewpetersen6116      0  15 ঘণ্টা আগে   \n",
       "4      @AshishVerma-dz9ug      0     1 দিন আগে   \n",
       "\n",
       "                                     cleaned_comment language  \n",
       "0                             india powerful country       en  \n",
       "1  common denominator islamist attach cause separ...       en  \n",
       "2  let talk child disappear mountbatten indian le...       en  \n",
       "3                               send master disaster       en  \n",
       "4  muslims want pakistan kill hindus million musl...       en  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_texts=[]\n",
    "languages=[]\n",
    "for text in df[comment_column]:\n",
    "    cleaned,lang=clean_text_nlp(text)\n",
    "    cleaned_texts.append(cleaned)\n",
    "    languages.append(lang)\n",
    "df[\"cleaned_comment\"]=cleaned_texts\n",
    "df[\"language\"]=languages\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0728c6aa",
   "metadata": {},
   "source": [
    "remove empty and duplicants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43d1ef3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>likes</th>\n",
       "      <th>published_at</th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>India is a very powerful country</td>\n",
       "      <td>@BoazMwadime-b1k</td>\n",
       "      <td>0</td>\n",
       "      <td>6 ঘণ্টা আগে</td>\n",
       "      <td>india powerful country</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>Common denominator with all Islamist is they a...</td>\n",
       "      <td>@clevelandwilliams5922</td>\n",
       "      <td>0</td>\n",
       "      <td>12 ঘণ্টা আগে</td>\n",
       "      <td>common denominator islamist attach cause separ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>Let’s talk about all the children that disappe...</td>\n",
       "      <td>@PeterWright-y3b</td>\n",
       "      <td>0</td>\n",
       "      <td>15 ঘণ্টা আগে</td>\n",
       "      <td>let talk child disappear mountbatten indian le...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>So they sent the master of disaster</td>\n",
       "      <td>@andrewpetersen6116</td>\n",
       "      <td>0</td>\n",
       "      <td>15 ঘণ্টা আগে</td>\n",
       "      <td>send master disaster</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>Muslims wanted Pakistan and killed hindus for ...</td>\n",
       "      <td>@AshishVerma-dz9ug</td>\n",
       "      <td>0</td>\n",
       "      <td>1 দিন আগে</td>\n",
       "      <td>muslims want pakistan kill hindus million musl...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment  \\\n",
       "0  K0B2qlb8eVI                   India is a very powerful country   \n",
       "1  K0B2qlb8eVI  Common denominator with all Islamist is they a...   \n",
       "2  K0B2qlb8eVI  Let’s talk about all the children that disappe...   \n",
       "3  K0B2qlb8eVI                So they sent the master of disaster   \n",
       "4  K0B2qlb8eVI  Muslims wanted Pakistan and killed hindus for ...   \n",
       "\n",
       "                   author  likes  published_at  \\\n",
       "0        @BoazMwadime-b1k      0   6 ঘণ্টা আগে   \n",
       "1  @clevelandwilliams5922      0  12 ঘণ্টা আগে   \n",
       "2        @PeterWright-y3b      0  15 ঘণ্টা আগে   \n",
       "3     @andrewpetersen6116      0  15 ঘণ্টা আগে   \n",
       "4      @AshishVerma-dz9ug      0     1 দিন আগে   \n",
       "\n",
       "                                     cleaned_comment language  \n",
       "0                             india powerful country       en  \n",
       "1  common denominator islamist attach cause separ...       en  \n",
       "2  let talk child disappear mountbatten indian le...       en  \n",
       "3                               send master disaster       en  \n",
       "4  muslims want pakistan kill hindus million musl...       en  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[df['cleaned_comment'].str.strip()!=\"\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81131ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>likes</th>\n",
       "      <th>published_at</th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>India is a very powerful country</td>\n",
       "      <td>@BoazMwadime-b1k</td>\n",
       "      <td>0</td>\n",
       "      <td>6 ঘণ্টা আগে</td>\n",
       "      <td>india powerful country</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>Common denominator with all Islamist is they a...</td>\n",
       "      <td>@clevelandwilliams5922</td>\n",
       "      <td>0</td>\n",
       "      <td>12 ঘণ্টা আগে</td>\n",
       "      <td>common denominator islamist attach cause separ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>Let’s talk about all the children that disappe...</td>\n",
       "      <td>@PeterWright-y3b</td>\n",
       "      <td>0</td>\n",
       "      <td>15 ঘণ্টা আগে</td>\n",
       "      <td>let talk child disappear mountbatten indian le...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>So they sent the master of disaster</td>\n",
       "      <td>@andrewpetersen6116</td>\n",
       "      <td>0</td>\n",
       "      <td>15 ঘণ্টা আগে</td>\n",
       "      <td>send master disaster</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>Muslims wanted Pakistan and killed hindus for ...</td>\n",
       "      <td>@AshishVerma-dz9ug</td>\n",
       "      <td>0</td>\n",
       "      <td>1 দিন আগে</td>\n",
       "      <td>muslims want pakistan kill hindus million musl...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment  \\\n",
       "0  K0B2qlb8eVI                   India is a very powerful country   \n",
       "1  K0B2qlb8eVI  Common denominator with all Islamist is they a...   \n",
       "2  K0B2qlb8eVI  Let’s talk about all the children that disappe...   \n",
       "3  K0B2qlb8eVI                So they sent the master of disaster   \n",
       "4  K0B2qlb8eVI  Muslims wanted Pakistan and killed hindus for ...   \n",
       "\n",
       "                   author  likes  published_at  \\\n",
       "0        @BoazMwadime-b1k      0   6 ঘণ্টা আগে   \n",
       "1  @clevelandwilliams5922      0  12 ঘণ্টা আগে   \n",
       "2        @PeterWright-y3b      0  15 ঘণ্টা আগে   \n",
       "3     @andrewpetersen6116      0  15 ঘণ্টা আগে   \n",
       "4      @AshishVerma-dz9ug      0     1 দিন আগে   \n",
       "\n",
       "                                     cleaned_comment language  \n",
       "0                             india powerful country       en  \n",
       "1  common denominator islamist attach cause separ...       en  \n",
       "2  let talk child disappear mountbatten indian le...       en  \n",
       "3                               send master disaster       en  \n",
       "4  muslims want pakistan kill hindus million musl...       en  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop_duplicates(subset=[\"cleaned_comment\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebbf6ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned comments saved to youtube_comments_cleaned.csv. Total rows: 391\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"youtube_comments_cleaned.csv\", index=False, encoding='utf-8-sig')\n",
    "print(f\"Cleaned comments saved to youtube_comments_cleaned.csv. Total rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a451ee9",
   "metadata": {},
   "source": [
    "relevant comment filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93a3c56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant data shape: (213, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>likes</th>\n",
       "      <th>published_at</th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>language</th>\n",
       "      <th>is_relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>India is a very powerful country</td>\n",
       "      <td>@BoazMwadime-b1k</td>\n",
       "      <td>0</td>\n",
       "      <td>6 ঘণ্টা আগে</td>\n",
       "      <td>india powerful country</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>Common denominator with all Islamist is they a...</td>\n",
       "      <td>@clevelandwilliams5922</td>\n",
       "      <td>0</td>\n",
       "      <td>12 ঘণ্টা আগে</td>\n",
       "      <td>common denominator islamist attach cause separ...</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>Let’s talk about all the children that disappe...</td>\n",
       "      <td>@PeterWright-y3b</td>\n",
       "      <td>0</td>\n",
       "      <td>15 ঘণ্টা আগে</td>\n",
       "      <td>let talk child disappear mountbatten indian le...</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>Muslims wanted Pakistan and killed hindus for ...</td>\n",
       "      <td>@AshishVerma-dz9ug</td>\n",
       "      <td>0</td>\n",
       "      <td>1 দিন আগে</td>\n",
       "      <td>muslims want pakistan kill hindus million musl...</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>It was a master plan by the west a divided Ind...</td>\n",
       "      <td>@greggarcia9842</td>\n",
       "      <td>0</td>\n",
       "      <td>1 দিন আগে</td>\n",
       "      <td>master plan west divide india good western power</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment  \\\n",
       "0  K0B2qlb8eVI                   India is a very powerful country   \n",
       "1  K0B2qlb8eVI  Common denominator with all Islamist is they a...   \n",
       "2  K0B2qlb8eVI  Let’s talk about all the children that disappe...   \n",
       "4  K0B2qlb8eVI  Muslims wanted Pakistan and killed hindus for ...   \n",
       "5  K0B2qlb8eVI  It was a master plan by the west a divided Ind...   \n",
       "\n",
       "                   author  likes  published_at  \\\n",
       "0        @BoazMwadime-b1k      0   6 ঘণ্টা আগে   \n",
       "1  @clevelandwilliams5922      0  12 ঘণ্টা আগে   \n",
       "2        @PeterWright-y3b      0  15 ঘণ্টা আগে   \n",
       "4      @AshishVerma-dz9ug      0     1 দিন আগে   \n",
       "5         @greggarcia9842      0     1 দিন আগে   \n",
       "\n",
       "                                     cleaned_comment language  is_relevant  \n",
       "0                             india powerful country       en         True  \n",
       "1  common denominator islamist attach cause separ...       en         True  \n",
       "2  let talk child disappear mountbatten indian le...       en         True  \n",
       "4  muslims want pakistan kill hindus million musl...       en         True  \n",
       "5   master plan west divide india good western power       en         True  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords=[\n",
    "    \"india\",\"pakistan\",\"kasmir\",\"modi\",\"imran\",\"army\",\"border\",\"war\",\"peace\",\"terrorism\"\n",
    "]\n",
    "df[\"is_relevant\"]=df[\"cleaned_comment\"].apply(lambda x: any(k in x for k in keywords))\n",
    "df_filtered=df[df[\"is_relevant\"]==True]\n",
    "print(f\"Relevant data shape: {df_filtered.shape}\")\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a76dfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 500 relevant comments to manual_label_data.csv for manual labeling.\n"
     ]
    }
   ],
   "source": [
    "df_sample=df_filtered.sample(n=500, random_state=42,replace=True)\n",
    "df_sample.to_csv(\"manual_label_data.csv\", index=False, encoding='utf-8-sig')\n",
    "print(\"Exported 500 relevant comments to manual_label_data.csv for manual labeling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e417d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.49.0)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (3.20.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.36.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/imac/Library/Python/3.12/lib/python/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/imac/Library/Python/3.12/lib/python/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/imac/Library/Python/3.12/lib/python/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/imac/Library/Python/3.12/lib/python/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/imac/Library/Python/3.12/lib/python/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "390e5f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>likes</th>\n",
       "      <th>published_at</th>\n",
       "      <th>cleaned_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>India is a very powerful country</td>\n",
       "      <td>@BoazMwadime-b1k</td>\n",
       "      <td>0</td>\n",
       "      <td>6 ঘণ্টা আগে</td>\n",
       "      <td>India is a very powerful country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>Common denominator with all Islamist is they a...</td>\n",
       "      <td>@clevelandwilliams5922</td>\n",
       "      <td>0</td>\n",
       "      <td>12 ঘণ্টা আগে</td>\n",
       "      <td>Common denominator with all Islamist is they a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>Let’s talk about all the children that disappe...</td>\n",
       "      <td>@PeterWright-y3b</td>\n",
       "      <td>0</td>\n",
       "      <td>15 ঘণ্টা আগে</td>\n",
       "      <td>Let’s talk about all the children that disappe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>So they sent the master of disaster</td>\n",
       "      <td>@andrewpetersen6116</td>\n",
       "      <td>0</td>\n",
       "      <td>15 ঘণ্টা আগে</td>\n",
       "      <td>So they sent the master of disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K0B2qlb8eVI</td>\n",
       "      <td>Muslims wanted Pakistan and killed hindus for ...</td>\n",
       "      <td>@AshishVerma-dz9ug</td>\n",
       "      <td>0</td>\n",
       "      <td>1 দিন আগে</td>\n",
       "      <td>Muslims wanted Pakistan and killed hindus for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment  \\\n",
       "0  K0B2qlb8eVI                   India is a very powerful country   \n",
       "1  K0B2qlb8eVI  Common denominator with all Islamist is they a...   \n",
       "2  K0B2qlb8eVI  Let’s talk about all the children that disappe...   \n",
       "3  K0B2qlb8eVI                So they sent the master of disaster   \n",
       "4  K0B2qlb8eVI  Muslims wanted Pakistan and killed hindus for ...   \n",
       "\n",
       "                   author  likes  published_at  \\\n",
       "0        @BoazMwadime-b1k      0   6 ঘণ্টা আগে   \n",
       "1  @clevelandwilliams5922      0  12 ঘণ্টা আগে   \n",
       "2        @PeterWright-y3b      0  15 ঘণ্টা আগে   \n",
       "3     @andrewpetersen6116      0  15 ঘণ্টা আগে   \n",
       "4      @AshishVerma-dz9ug      0     1 দিন আগে   \n",
       "\n",
       "                                     cleaned_comment  \n",
       "0                   India is a very powerful country  \n",
       "1  Common denominator with all Islamist is they a...  \n",
       "2  Let’s talk about all the children that disappe...  \n",
       "3                So they sent the master of disaster  \n",
       "4  Muslims wanted Pakistan and killed hindus for ...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\"youtube_comments.csv\")\n",
    "\n",
    "# Ensure cleaned_comment exists even if the raw CSV has only comment/text columns.\n",
    "if \"cleaned_comment\" not in df.columns:\n",
    "    candidate_cols = [c for c in df.columns if \"comment\" in str(c).lower() or \"text\" in str(c).lower()]\n",
    "    if not candidate_cols:\n",
    "        raise KeyError(f\"No comment/text column found. Available columns: {list(df.columns)}\")\n",
    "    df[\"cleaned_comment\"] = df[candidate_cols[0]]\n",
    "\n",
    "# Normalize and keep non-empty text only.\n",
    "df[\"cleaned_comment\"] = df[\"cleaned_comment\"].fillna(\"\").astype(str)\n",
    "df = df[df[\"cleaned_comment\"].str.strip() != \"\"].copy()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdc162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_label(text):\n",
    "    result=classifier(str(text))[0]\n",
    "    label_id=result['label']\n",
    "    if label_id == \"LABEL_0\":\n",
    "        return \"negative\"\n",
    "    elif label_id == \"LABEL_1\":\n",
    "        return \"neutral\"\n",
    "    else :\n",
    "        return \"positive\"\n",
    "df['label']=df['cleaned_comment'].apply(auto_label)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
